### Environment Configuration Template
### Note: All commented-out values show the system defaults

### Required API keys
OPENAI_API_KEY=<YOUR-OPENAI_API_KEY>
TAVILY_API_KEY=<YOUR-TAVILY_API_KEY>

### General LLM settings
LLM_PROVIDER=openai  # Options: openai, deepseek
LLM_MODEL=gpt-4o     # Model name to use with the selected provider
# LLM_TEMPERATURE=0.0  # Default. Controls randomness in responses (0.0 to 1.0)
# LLM_MAX_TOKENS=1024  # Default. Maximum number of tokens in the response

### DEEPSEEK specific settings (required if LLM_PROVIDER=deepseek)
# DEEPSEEK_API_KEY=<YOUR-DEEPSEEK_API_KEY>
# DEEPSEEK_API_BASE=https://api.deepseek.com  # Default. Base URL for Deepseek API

### Tavily search engine additional settings
# TAVILY_API_URL=https://api.tavily.ai       # Default. Tavily API base URL
# TAVILY_SEARCH_DEPTH=basic                  # Default. Search depth (basic or advanced)
# TAVILY_INCLUDE_ANSWER=True                 # Default. Include AI-generated answer in results
# TAVILY_TOPIC=news                          # Default. Default search topic
# TAVILY_INCLUDE_RAW_CONTENT=True            # Default. Include raw content in search results
# TAVILY_MAX_RESULTS=3                       # Default. Maximum number of search results to return
